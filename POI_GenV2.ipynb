{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from random import choice, choices, randrange\n",
    "from joblib import Parallel, delayed\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import BOOK_GenBehaviour as bkbeh\n",
    "from src import BOOK_Grouping as bkgroup\n",
    "from src import BOOK_Trip as bktrip\n",
    "from src import FLY_Booking as fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city = pd.read_csv('data/geoCrosswalk/GeoCrossWalkMed.csv')\n",
    "df_flight = pd.read_csv('data/flightData/EU_flight_new.csv')\n",
    "df_hubs = pd.read_csv('data/geoCrosswalk/ReverseHubsV2.csv')\n",
    "route = pd.read_csv('data/flightData/route_all.csv')\n",
    "crosswalk = pd.read_csv('data/geoCrosswalk/GeoCrossWalkMed.csv')\n",
    "bus_stay_day = pd.read_csv('data/business_stay.csv')['bus_stay_day'].tolist()\n",
    "bus_stay_weight = pd.read_csv('data/business_stay.csv')['bus_stay_weight'].tolist()\n",
    "vac_stay_day = pd.read_csv('data/vacation_stay.csv')['vac_stay_day'].tolist()\n",
    "vac_stay_weight = pd.read_csv('data/vacation_stay.csv')['vac_stay_weight'].tolist()\n",
    "personas = pd.read_csv('data/personas.csv')['personas'].tolist()\n",
    "weight = pd.read_csv('data/personas.csv')['weight'].tolist()\n",
    "agencies = pd.read_csv('data/agencies.csv')['agencies'].tolist()\n",
    "agency_weight = pd.read_csv('data/agencies.csv')['agency_weight'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_locale_gen(locale):\n",
    "    try:\n",
    "        return Faker(locale)\n",
    "    except AttributeError:\n",
    "        return Faker('en')\n",
    "\n",
    "def generate_households(num_households, df_city):\n",
    "    \"\"\"\n",
    "    Generate synthetic household data for flight passenger simulation.\n",
    "    \n",
    "    Parameters:\n",
    "    - num_households: int, number of households to generate.\n",
    "    - df_city: DataFrame, contains city data including available languages.\n",
    "    - available_langs: list, languages available for selection.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with household information.\n",
    "    \"\"\"\n",
    "\n",
    "    # HH_num\tGenderHOH\tAgeHOH\tSizeHH\tHHID\tHH_ISO\tHHType\tLang\tLang_P\tSurname\tAddress\tPostCode\tCountry\tNationalityLP\tNationalityNat\n",
    "    households = []\n",
    "    available_langs = df_city['Lang'].tolist()\n",
    "    for i in range(num_households):\n",
    "        HH_ISO = choice(df_city['HH_ISO'].tolist())\n",
    "        HHID = f\"POI_{i}\"\n",
    "        gender = choice([\"M\", \"F\"])\n",
    "        HHType = choice([\"T1\", \"T2\"])\n",
    "        age = randrange(5, 17) if HHType == 'T1' else randrange(28, 56)\n",
    "        sizeHH = 1 if HHType == 'T1' else 2\n",
    "        \n",
    "        lang = choice(available_langs) if np.random.random() < 0.2 else 'en'  # Simplified language logic\n",
    "        faker_gen = safe_locale_gen(lang)\n",
    "        \n",
    "        # surname = faker_gen.last_name()\n",
    "        address = faker_gen.address()\n",
    "        postcode = faker_gen.postcode()\n",
    "        country = faker_gen.country()\n",
    "        payment_vendor = faker_gen.credit_card_provider()\n",
    "        payment_expiry = faker_gen.credit_card_expire(start=\"now\", end=\"+10y\", date_format=\"%d/%m/%y\")\n",
    "        payment_number = faker_gen.credit_card_number(card_type=None)\n",
    "        \n",
    "        households.append([i, gender, age, sizeHH, HHID, HH_ISO, HHType, lang, address, postcode, country, payment_vendor, payment_expiry, payment_number])\n",
    "    \n",
    "    columns = ['HH_num', 'GenderHOH', 'AgeHOH', 'SizeHH', 'HHID', 'HH_ISO', 'HHType', 'Lang', 'Address', 'PostCode', 'Country', 'PaymentInfo_VendorCode', 'PaymentInfo_ExpiryDate', 'PaymentInfo_AccountNbr']\n",
    "    return pd.DataFrame(households, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_dob(age):\n",
    "    \"\"\"\n",
    "    Generate a Date of Birth for the given age.\n",
    "    \"\"\"\n",
    "    today = datetime.today()\n",
    "    start_of_year = datetime(today.year - age, 1, 1)\n",
    "    end_of_year = datetime(today.year - age, 12, 31)\n",
    "    random_days = timedelta(days=(end_of_year - start_of_year).days * np.random.random())\n",
    "    dob = start_of_year + random_days\n",
    "    return dob.strftime('%d/%m/%Y')\n",
    "\n",
    "\n",
    "def generate_typ_names(faker_gen, doc_first_name, doc_surname):\n",
    "    \"\"\"\n",
    "    Generate typology names with a 20% chance of being different from the document names.\n",
    "    \"\"\"\n",
    "    if np.random.rand() < 0.5:  # 20% chance\n",
    "        typ_first_name = faker_gen.first_name()\n",
    "        typ_surname = faker_gen.last_name()\n",
    "    else:\n",
    "        typ_first_name = doc_first_name\n",
    "        typ_surname = doc_surname\n",
    "    return typ_first_name, typ_surname\n",
    "\n",
    "\n",
    "def populate_passengers(household_row, df_city):\n",
    "    \"\"\"\n",
    "    Populate passengers for a given household, ensuring diversity and generating comprehensive passenger attributes.\n",
    "    Now includes a 20% chance for typology names to differ from document names.\n",
    "    \n",
    "    Parameters:\n",
    "    - household_row: Series, a row from the household DataFrame.\n",
    "    - df_city: DataFrame, contains city data for determining locales.\n",
    "    \n",
    "    Returns:\n",
    "    - List of comprehensive passenger data for the household.\n",
    "    \"\"\"\n",
    "    passengers = []\n",
    "    HHID = household_row['HHID']\n",
    "    HHType = household_row['HHType']\n",
    "    base_age = household_row['AgeHOH']\n",
    "    lang = household_row['Lang']\n",
    "    payment_vendor = household_row['PaymentInfo_VendorCode']\n",
    "    payment_expiry = household_row['PaymentInfo_ExpiryDate']\n",
    "    payment_number = household_row['PaymentInfo_AccountNbr']    \n",
    "    faker_gen = safe_locale_gen(lang)\n",
    "    print(household_row['SizeHH'])\n",
    "    for j in range(household_row['SizeHH']):\n",
    "        \n",
    "        P_num = j\n",
    "        P_ID = f\"{HHID}_{j+1}\"\n",
    "        print(\"HHID:\", HHID, \"j:\", j, \"P_ID:\", P_ID, \"HHType:\", HHType) \n",
    "        if HHType == 'T1' or j == 0:\n",
    "            age = base_age\n",
    "            gender = household_row['GenderHOH']\n",
    "        else:\n",
    "            age = randrange(5, 17)\n",
    "            gender = choices(['M', 'F'], weights=[0.3, 0.7])[0]\n",
    "\n",
    "        first_name = faker_gen.first_name_male() if gender == 'M' else faker_gen.first_name_female()\n",
    "        surname = faker_gen.last_name()\n",
    "        dob = generate_dob(age)\n",
    "        free_email = faker_gen.free_email()\n",
    "        # payment_vendor = faker_gen.credit_card_provider()\n",
    "        # payment_expiry = faker_gen.credit_card_expire(start=\"now\", end=\"+10y\", date_format=\"%d/%m/%y\")\n",
    "        # payment_number = faker_gen.credit_card_number(card_type=None)\n",
    "        work_email = faker_gen.company_email()\n",
    "        docs_expiry = (datetime.today() + timedelta(days=365 * 10)).strftime('%Y-%m-%d')  # Assuming 10 years from now\n",
    "        \n",
    "        doc_first_name = unidecode(first_name)\n",
    "        doc_surname = unidecode(surname)  # Document names are the real names\n",
    "        typ_first_name, typ_surname = generate_typ_names(faker_gen, doc_first_name, doc_surname)  # Generate TYP names\n",
    "        NationalityNat = choice(df_city['HH_ISO'].tolist())\n",
    "\n",
    "\n",
    "        passenger = [\n",
    "            P_num, HHID, P_ID, age, \n",
    "            f\"{5 * (age // 5)}-{5 * (age // 5) + 4}\" if age < 100 else \"100+\",  # AgeRange\n",
    "            f\"AGE{age // 5 + 1}\" if age < 100 else \"AGE21\",  # AgeGroup\n",
    "            gender, household_row['GenderHOH'], base_age, household_row['SizeHH'],\n",
    "            household_row['HH_ISO'], HHType, lang, surname, household_row['Address'],\n",
    "            household_row['PostCode'], household_row['Country'], first_name, dob, free_email,\n",
    "            payment_vendor, payment_expiry, payment_number, work_email, docs_expiry,\n",
    "            doc_first_name, doc_surname, typ_first_name, typ_surname, NationalityNat\n",
    "            ]\n",
    "    # No placeholder for P_num is added here\n",
    "        passengers.append(passenger)\n",
    "    \n",
    "    return passengers\n",
    "\n",
    "def generate_passenger_data(df_HH, df_city):\n",
    "    \"\"\"\n",
    "    Generate comprehensive passenger data for all households.\n",
    "    \n",
    "    Parameters:\n",
    "    - df_HH: DataFrame, household data.\n",
    "    - df_city: DataFrame, city data for locale information.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with comprehensive passenger data.\n",
    "    \"\"\"\n",
    "    # passenger_data = Parallel(n_jobs=-1)(delayed(populate_passengers)(row, df_city) for index, row in df_HH.iterrows())\n",
    "    # passenger_data = [p for sublist in passenger_data for p in sublist]  # Flatten the list of lists\n",
    "\n",
    "    passenger_data = []\n",
    "    for index, row in df_HH.iterrows():\n",
    "        passengers = populate_passengers(row, df_city)\n",
    "        passenger_data.extend(passengers) \n",
    "    \n",
    "    columns = [\n",
    "        'P_num', 'HHID', 'P_ID', 'P_AGE', 'AgeRange', 'AgeGroup', 'P_Gender', 'GenderHOH', 'AgeHOH', 'SizeHH', 'HH_ISO', 'HHType', 'Lang',\n",
    "        'Surname', 'Address', 'PostCode', 'Country', 'FirstName', 'DOB', 'FreeEmail',\n",
    "        'PaymentInfo_VendorCode', 'PaymentInfo_ExpiryDate', 'PaymentInfo_AccountNbr',\n",
    "        'WorkEmail', 'DOCS_ExpiryDate', 'DOC_FirstName', 'DOC_Surname', 'TYP_FirstName',\n",
    "        'TYP_Surname', 'NationalityNat'\n",
    "    ]\n",
    "    df_passengers = pd.DataFrame(passenger_data, columns=columns)\n",
    "    \n",
    "    return df_passengers\n",
    "\n",
    "def finalize_data(df):\n",
    "    \"\"\"\n",
    "    Finalize the DataFrame by adding P_num and ensuring the correct column order.\n",
    "    \"\"\"\n",
    "    df.insert(0, 'P_num', range(1, len(df) + 1))  # Insert P_num at the beginning\n",
    "    column_order = [\n",
    "        'P_num', 'HHID', 'P_ID', 'P_AGE', 'AgeRange', 'AgeGroup', 'P_GENDER', 'GenderHOH', 'AgeHOH', 'SizeHH', 'HH_ISO', 'HHType', 'Lang',\n",
    "        'Surname', 'Address', 'PostCode', 'Country', 'FirstName', 'DOB', 'FreeEmail', 'PaymentInfo_VendorCode', 'PaymentInfo_ExpiryDate',\n",
    "        'PaymentInfo_AccountNbr', 'WorkEmail', 'DOCS_ExpiryDate', 'DOC_FirstName', 'DOC_Surname', 'TYP_FirstName', 'TYP_Surname'\n",
    "    ]\n",
    "    return df[column_order]\n",
    "\n",
    "# Note: Ensure that df_city and df_HH are properly set up before calling generate_passenger_data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce_typos(text, typo_rate):\n",
    "    typo_text = list(text)\n",
    "    for i in range(len(typo_text)-1):\n",
    "        if np.random() < typo_rate:\n",
    "            # Introduce a typo (e.g., swap with the next character)\n",
    "            typo_text[i], typo_text[i+1] = typo_text[i+1], typo_text[i]\n",
    "    return ''.join(typo_text)\n",
    "\n",
    "def docIDs(row):\n",
    "\n",
    "    data={}\n",
    "    random_number = np.random()\n",
    "    if random_number > 0.005:\n",
    "        data['TYP_FirstName'] = row['DOC_FirstName']\n",
    "        data['TYP_Surname'] = row['DOC_Surname']\n",
    "        # data['TYP_DOB'] = str(row['DOB'])\n",
    "    else:\n",
    "        data['TYP_FirstName'] = introduce_typos(row['DOC_FirstName'], typo_rate=0.2)\n",
    "        data['TYP_Surname'] = introduce_typos(row['DOC_Surname'], typo_rate=0.2)\n",
    "        # data['TYP_DOB'] = introduce_dob_typos2(str(row['DOB']), typo_rate=0.2)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "HHID: POI_0 j: 0 P_ID: POI_0_1 HHType: T2\n",
      "HHID: POI_0 j: 1 P_ID: POI_0_2 HHType: T2\n",
      "2\n",
      "HHID: POI_1 j: 0 P_ID: POI_1_1 HHType: T2\n",
      "HHID: POI_1 j: 1 P_ID: POI_1_2 HHType: T2\n",
      "2\n",
      "HHID: POI_2 j: 0 P_ID: POI_2_1 HHType: T2\n",
      "HHID: POI_2 j: 1 P_ID: POI_2_2 HHType: T2\n",
      "1\n",
      "HHID: POI_3 j: 0 P_ID: POI_3_1 HHType: T1\n",
      "2\n",
      "HHID: POI_4 j: 0 P_ID: POI_4_1 HHType: T2\n",
      "HHID: POI_4 j: 1 P_ID: POI_4_2 HHType: T2\n",
      "1\n",
      "HHID: POI_5 j: 0 P_ID: POI_5_1 HHType: T1\n",
      "2\n",
      "HHID: POI_6 j: 0 P_ID: POI_6_1 HHType: T2\n",
      "HHID: POI_6 j: 1 P_ID: POI_6_2 HHType: T2\n",
      "1\n",
      "HHID: POI_7 j: 0 P_ID: POI_7_1 HHType: T1\n",
      "1\n",
      "HHID: POI_8 j: 0 P_ID: POI_8_1 HHType: T1\n",
      "2\n",
      "HHID: POI_9 j: 0 P_ID: POI_9_1 HHType: T2\n",
      "HHID: POI_9 j: 1 P_ID: POI_9_2 HHType: T2\n",
      "1\n",
      "HHID: POI_10 j: 0 P_ID: POI_10_1 HHType: T1\n",
      "1\n",
      "HHID: POI_11 j: 0 P_ID: POI_11_1 HHType: T1\n",
      "1\n",
      "HHID: POI_12 j: 0 P_ID: POI_12_1 HHType: T1\n",
      "1\n",
      "HHID: POI_13 j: 0 P_ID: POI_13_1 HHType: T1\n",
      "1\n",
      "HHID: POI_14 j: 0 P_ID: POI_14_1 HHType: T1\n",
      "2\n",
      "HHID: POI_15 j: 0 P_ID: POI_15_1 HHType: T2\n",
      "HHID: POI_15 j: 1 P_ID: POI_15_2 HHType: T2\n",
      "2\n",
      "HHID: POI_16 j: 0 P_ID: POI_16_1 HHType: T2\n",
      "HHID: POI_16 j: 1 P_ID: POI_16_2 HHType: T2\n",
      "2\n",
      "HHID: POI_17 j: 0 P_ID: POI_17_1 HHType: T2\n",
      "HHID: POI_17 j: 1 P_ID: POI_17_2 HHType: T2\n",
      "1\n",
      "HHID: POI_18 j: 0 P_ID: POI_18_1 HHType: T1\n",
      "2\n",
      "HHID: POI_19 j: 0 P_ID: POI_19_1 HHType: T2\n",
      "HHID: POI_19 j: 1 P_ID: POI_19_2 HHType: T2\n"
     ]
    }
   ],
   "source": [
    "num_HH = 20\n",
    "df_HH = generate_households(num_HH, df_city)\n",
    "df_passengers = generate_passenger_data(df_HH, df_city)\n",
    "# df_passengers_final = finalize_data(df_passengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_HH.shape: (20, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammadfathifadlian/Documents/GitHub/Synthetic-PNR-Generation/src/BOOK_Trip.py:95: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged['ISO_Travel'].fillna(merged['HH_ISO'], inplace=True)\n",
      "/Users/muhammadfathifadlian/Documents/GitHub/Synthetic-PNR-Generation/src/BOOK_Trip.py:76: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_HH['IATA_O'].fillna(pd.Series(np.random.choice(['LHR', 'CDG', 'IST', 'DXB', 'AUH'], size=len(df_HH))), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_behaviour_shape:  (20, 2)\n",
      "df_behaviour_shape:  (20, 3)\n",
      "df_behaviour_shape:  (20, 4)\n",
      "df_sizeHH: 0     2\n",
      "1     2\n",
      "2     2\n",
      "3     1\n",
      "4     2\n",
      "5     1\n",
      "6     2\n",
      "7     1\n",
      "8     1\n",
      "9     2\n",
      "10    1\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    1\n",
      "15    2\n",
      "16    2\n",
      "17    2\n",
      "18    1\n",
      "19    2\n",
      "Name: SizeHH, dtype: int64\n",
      "df_sizeHH: 0     2\n",
      "1     2\n",
      "2     2\n",
      "3     1\n",
      "4     2\n",
      "5     1\n",
      "6     2\n",
      "7     1\n",
      "8     1\n",
      "9     2\n",
      "10    1\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    1\n",
      "15    2\n",
      "16    2\n",
      "17    2\n",
      "18    1\n",
      "19    2\n",
      "Name: SizeHH, dtype: int64\n",
      "df_sizeHH: 0     2\n",
      "1     2\n",
      "2     2\n",
      "3     1\n",
      "4     2\n",
      "5     1\n",
      "6     2\n",
      "7     1\n",
      "8     1\n",
      "9     2\n",
      "10    1\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    1\n",
      "15    2\n",
      "16    2\n",
      "17    2\n",
      "18    1\n",
      "19    2\n",
      "Name: SizeHH, dtype: int64\n",
      "Warning: 'business_group' is empty. No data to process.\n",
      "done business group\n",
      "done leisure\n",
      "done SOI\n",
      "0    IST-SEN-SOI-ID0\n",
      "1    IST-DUB-SOI-ID0\n",
      "2    DXB-CDG-SOI-ID0\n",
      "3    DXB-LIS-SOI-ID0\n",
      "4    IST-CDG-SOI-ID0\n",
      "Name: init_id, dtype: object\n",
      "Index(['init_id', 'list_of_passengers', 'route', 'num_in_party',\n",
      "       'BookingAgency', 'BookingDay', 'Unnamed: 0', 'IATA_O', 'IATA_D',\n",
      "       'HH_ISO_D', 'region_D', 'HH_ISO_O', 'region_O', 'LegHH_ISO',\n",
      "       'LegRegion', 'Origin', 'Destination', 'fixRoute', 'Leg_fixRoute'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammadfathifadlian/Documents/GitHub/Synthetic-PNR-Generation/src/BOOK_Grouping.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[f'Leg_fixRoute_{i}'].fillna(0, inplace=True)\n",
      "/Users/muhammadfathifadlian/Documents/GitHub/Synthetic-PNR-Generation/src/BOOK_Grouping.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[f'Leg_fixRoute_{i}'].fillna(0, inplace=True)\n",
      "/Users/muhammadfathifadlian/Documents/GitHub/Synthetic-PNR-Generation/src/BOOK_Grouping.py:98: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[f'Leg_fixRoute_{i}'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_city, df_HH = bktrip.original_city_assign_init(df_HH, df_flight, df_hubs)\n",
    "df_behaviour, df_behaviour_complete = bkbeh.generate_behaviour(df_HH, df_flight, ['SOI'], [1], 3, crosswalk)\n",
    "df_group = bkgroup.grouping_init(df_behaviour_complete, agencies, agency_weight, route, bus_stay_day, bus_stay_weight, vac_stay_day, vac_stay_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group.to_csv('data/synthesizedData/group_soi.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
